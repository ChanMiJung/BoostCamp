{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_BERT기반두문장관계분류모델학습_두문장관계분류학습.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SFcdbaSa6d3"
      },
      "source": [
        "# BERT 모델을 활용한 두 문장 관계 분류 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJAMXQMuas08"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QArCDIVtbB60"
      },
      "source": [
        "import torch\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jv8YcVXbCrf"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9latvMrbElJ"
      },
      "source": [
        "* 학습 데이터 확인\n",
        "  * 두 문장과 label이 tab(\\t)으로 구분되어있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIRZi3sDbDRW"
      },
      "source": [
        "data = open('/content/para_kqc_sim_data.txt', 'r', encoding='utf-8')\n",
        "lines = data.readlines()\n",
        "\n",
        "# 데이터셋 구조 확인\n",
        "print(lines[0:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4Dfw1ZtbUXl"
      },
      "source": [
        "import random\n",
        "random.shuffle(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQJYjnOwbcsV"
      },
      "source": [
        "* train data와 test data 구성\n",
        "  * train data 80%, test data 20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnPGNMtcbU_R"
      },
      "source": [
        "train = {'sent_a':[], 'sent_b':[], 'label':[]}\n",
        "test = {'sent_a':[], 'sent_b':[], 'label':[]}\n",
        "for i, line in enumerate(lines):\n",
        "    if i < len(lines) * 0.8:\n",
        "        line = line.strip()\n",
        "        train['sent_a'].append(line.split('\\t')[0])\n",
        "        train['sent_b'].append(line.split('\\t')[1])\n",
        "        train['label'].append(int(line.split('\\t')[2]))\n",
        "    else:\n",
        "        line = line.strip()\n",
        "        test['sent_a'].append(line.split('\\t')[0])\n",
        "        test['sent_b'].append(line.split('\\t')[1])\n",
        "        test['label'].append(int(line.split('\\t')[2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GINFMJq6bYYg"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1_2QzVobZNe"
      },
      "source": [
        "train_data = pd.DataFrame({\"sent_a\":train['sent_a'], \"sent_b\":train['sent_b'], \"label\":train['label']})\n",
        "test_data = pd.DataFrame({\"sent_a\":test['sent_a'], \"sent_b\":test['sent_b'], \"label\":test['label']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWJcCgLxbxQf"
      },
      "source": [
        "* 중복 데이터 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ZzCe-SbZ9-"
      },
      "source": [
        "# 데이터 중복을 제외한 갯수 확인\n",
        "print(\"학습데이터 : \",train_data.groupby(['sent_a', 'sent_b']).ngroups,\" 라밸 : \",train_data['label'].nunique())\n",
        "# 학습데이터 :  15183  라밸 :  2\n",
        "print(\"데스트 데이터 : \",test_data.groupby(['sent_a', 'sent_b']).ngroups,\" 라벨 : \",test_data['label'].nunique())\n",
        "# 데스트 데이터 :  3796  라벨 :  2\n",
        "\n",
        "# 중복 데이터 제거\n",
        "train_data.drop_duplicates(subset=['sent_a', 'sent_b'], inplace= True)\n",
        "test_data.drop_duplicates(subset=['sent_a', 'sent_b'], inplace= True)\n",
        "\n",
        "# 데이터셋 갯수 확인\n",
        "print('중복 제거 후 학습 데이터셋 : {}'.format(len(train_data)))\n",
        "# 중복 제거 후 학습 데이터셋 : 15183\n",
        "print('중복 제거 후 테스트 데이터셋 : {}'.format(len(test_data)))\n",
        "# 중복 제거 후 테스트 데이터셋 : 3796"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTLtUqstbzgC"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjE3SsOJb0PQ"
      },
      "source": [
        "* null 데이터 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHLV25P9b1li"
      },
      "source": [
        "# null 데이터 제거\n",
        "train_data.replace('', np.nan, inplace=True)\n",
        "test_data.replace('', np.nan, inplace=True)\n",
        "\n",
        "train_data = train_data.dropna(how = 'any')\n",
        "test_data = test_data.dropna(how = 'any')\n",
        "\n",
        "print('null 제거 후 학습 데이터셋 : {}'.format(len(train_data)))\n",
        "# null 제거 후 학습 데이터셋 : 15183\n",
        "print('null 제거 후 테스트 데이터셋 : {}'.format(len(test_data)))\n",
        "# null 제거 후 테스트 데이터셋 : 3796"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCiMEa3nb2bh"
      },
      "source": [
        "print(train_data['sent_a'][0])\n",
        "# 오늘 관악구 습도는?\n",
        "print(train_data['sent_b'][0])\n",
        "# 오늘 관악구 습도 알고싶습니다.\n",
        "print(train_data['label'][0])\n",
        "# 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo6x-2iFcFoE"
      },
      "source": [
        "# 학습 전제 문장 길이조사\n",
        "print('학습 전제 문장의 최대 길이 :',max(len(l) for l in train_data['sent_a']))\n",
        "# 학습 전제 문장의 최대 길이 : 49\n",
        "print('전제 문장의 평균 길이 :',sum(map(len, train_data['sent_a']))/len(train_data['sent_a']))\n",
        "# 전제 문장의 평균 길이 : 22.360995850622405\n",
        "\n",
        "plt.hist([len(s) for s in train_data['sent_a']], bins=50)\n",
        "plt.xlabel('length of data')\n",
        "plt.ylabel('number of data')\n",
        "plt.show()\n",
        "\n",
        "# 학습 가정 문장 길이조사\n",
        "print('학습 가정 문장의 최대 길이 :',max(len(l) for l in train_data['sent_b']))\n",
        "# 학습 가정 문장의 최대 길이 : 65\n",
        "print('가정 문장의 평균 길이 :',sum(map(len, train_data['sent_b']))/len(train_data['sent_b']))\n",
        "# 가정 문장의 평균 길이 : 25.547322663505238\n",
        "\n",
        "plt.hist([len(s) for s in train_data['sent_b']], bins=50)\n",
        "plt.xlabel('length of data')\n",
        "plt.ylabel('number of data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD1S4afLcUQZ"
      },
      "source": [
        "* BERT를 사용하여 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe6pir9hcNzm"
      },
      "source": [
        "# Store the model we want to use\n",
        "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
        "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa-CFdfzca1Q"
      },
      "source": [
        "* tokenizer에서 두 문장 관계 분류 task에서 문장 2개를 input으로 넣음\n",
        "  * tokenizer가 자동으로 `[CLS] sentenceA [SEP] sentenceB [SEP]` 형태로 token을 부착하여 tokenizing을 함\n",
        "  * token_type_ids를 segmentA는 0, segmentB는 1로 tagging함\n",
        "\n",
        "* train data 전체를 한번에 embedding함\n",
        "  * input : list => output : list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_zF5nMJcOj-"
      },
      "source": [
        "tokenized_train_sentences = tokenizer(\n",
        "    list(train_data['sent_a'][0:]),\n",
        "    list(train_data['sent_b'][0:]),\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True,\n",
        "    max_length=64\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4xhSZwVdhZp"
      },
      "source": [
        "* `attention_mask` : 실제 분류를 위해 사용되는 데이터는 1, 나머지는 0으로 tagging됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "178UC_RPcSJX"
      },
      "source": [
        "print(tokenized_train_sentences[0])\n",
        "# Encoding(num_tokens=64, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
        "print(tokenized_train_sentences[0].tokens)\n",
        "# ['[CLS]', '오', '##늘', '관', '##악', '##구', '습', '##도는', '?', '[SEP]', '오', '##늘', '관', '##악', '##구', '습', '##도', '알', '##고', '##싶', '##습', '##니다', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
        "print(tokenized_train_sentences[0].ids)\n",
        "# [101, 9580, 118762, 8900, 119110, 17196, 9482, 60884, 136, 102, 9580, 118762, 8900, 119110, 17196, 9482, 12092, 9524, 11664, 119088, 119081, 48345, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "print(tokenized_train_sentences[0].attention_mask)\n",
        "# [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gLMyVgGdqhf"
      },
      "source": [
        " * 평가를 위한 test data tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkUDWFj7cWxE"
      },
      "source": [
        "tokenized_test_sentences = tokenizer(\n",
        "    list(test_data['sent_a'][0:]),\n",
        "    list(test_data['sent_b'][0:]),\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True,\n",
        "    max_length=64\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK6iPlx0dyzS"
      },
      "source": [
        "* label 저장 및 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uk8-5H5cXmp"
      },
      "source": [
        "train_label = train_data['label'].values[0:]\n",
        "test_label = test_data['label'].values[0:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyhz6EtrcYNd"
      },
      "source": [
        "print(train_label[0]) # 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R_UVDqRd64N"
      },
      "source": [
        "* `__getitem__()` : step이 진행됨에 따라 model에 지속적으로 입력되는 데이터\n",
        "  * input : tokenizer를 통해서 나온 결과(key, value)와 사전에 정의된 label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIaybvCXdWFL"
      },
      "source": [
        "class MultiSentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCjGn_EEdYXb"
      },
      "source": [
        "train_dataset = MultiSentDataset(tokenized_train_sentences, train_label)\n",
        "test_dataset = MultiSentDataset(tokenized_test_sentences, test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jyou8XiMeWs_"
      },
      "source": [
        "* BERT를 활용하여 train\n",
        "  * model 입장에서 한 문장이든지 두 문장이든지 상관없이 tokenize된 sentence가 input으로 들어가고, 마지막에 [CLS] token 하나만 분류를 하기 때문에 단일문장분류(`BertForSequenceClassification`)에서 사용했던 model 사용이 가능함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hht3uXy8dZNU"
      },
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments,  BertConfig\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=500,\n",
        "    save_total_limit=2,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MBDkH4Je8C9"
      },
      "source": [
        "* model initialized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOP2bsRMdaKJ"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2) \n",
        "model.parameters\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP9m8RRyfFJr"
      },
      "source": [
        "* evaluation 결과 출력하는 `compute_metrics` 함수 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eksSknqhdbj5"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4kvzW4RdcYJ"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,             # evaluation dataset\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdmXDQQUddH7"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_mnpo0Odeyk"
      },
      "source": [
        "trainer.evaluate(eval_dataset=test_dataset)\n",
        "'''\n",
        "{'epoch': 3.0,\n",
        " 'eval_accuracy': 0.9802423603793466,\n",
        " 'eval_f1': 0.9792186201163757,\n",
        " 'eval_loss': 0.0979667603969574,\n",
        " 'eval_precision': 0.9746276889134032,\n",
        " 'eval_recall': 0.9838530066815144,\n",
        " 'eval_runtime': 7.0701,\n",
        " 'eval_samples_per_second': 536.911}\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-B5aQnfdfwD"
      },
      "source": [
        "trainer.save_model('./results')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPCJ9_cpd3U0"
      },
      "source": [
        "# native training using torch\n",
        "\n",
        "# bert_config = BertConfig.from_pretrained(MODEL_NAME)\n",
        "# bert_config.num_labels = 3\n",
        "# model = BertForSequenceClassification(bert_config) \n",
        "# model.to(device)\n",
        "# model.train()\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# for epoch in range(3):\n",
        "#     for batch in train_loader:\n",
        "#         optim.zero_grad()\n",
        "#         input_ids = batch['input_ids'].to(device)\n",
        "#         attention_mask = batch['attention_mask'].to(device)\n",
        "#         labels = batch['labels'].to(device)\n",
        "#         outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "#         loss = outputs[0]\n",
        "#         loss.backward()\n",
        "#         optim.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRBYV41CfcTe"
      },
      "source": [
        "* prediction 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkjDR385e6gp"
      },
      "source": [
        "# predict함수\n",
        "# 0: \"non_similar\", 1: \"similar\"\n",
        "def sentences_predict(sent_A, sent_B):\n",
        "    model.eval()\n",
        "    tokenized_sent = tokenizer(\n",
        "            sent_A,\n",
        "            sent_B,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            max_length=64\n",
        "    )\n",
        "    \n",
        "    tokenized_sent.to('cuda:0')\n",
        "    with torch.no_grad():# 그라디엔트 계산 비활성화\n",
        "        outputs = model(\n",
        "            input_ids=tokenized_sent['input_ids'],\n",
        "            attention_mask=tokenized_sent['attention_mask'],\n",
        "            token_type_ids=tokenized_sent['token_type_ids']\n",
        "            )\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    result = np.argmax(logits) # softmax를 통과하고 나온 가장 높은 점수를 가진 index를 return\n",
        "\n",
        "    if result == 0:\n",
        "      result = 'non_similar'\n",
        "    elif result == 1:\n",
        "      result = 'similar'\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENF75PV6fPL3"
      },
      "source": [
        "print(sentences_predict('오늘 날씨가 어때요?','오늘의 날씨를 알려줘')) # similar\n",
        "print(sentences_predict('오늘 날씨가 어때요?','기분 진짜 안좋다.')) # non_similar\n",
        "print(sentences_predict('오늘 날씨가 어때요?','오늘 기분 어떠세요?')) # non_similar\n",
        "print(sentences_predict('오늘 날씨가 어때요?','오늘 기분이 어때요?')) # non_similar\n",
        "print(sentences_predict('오늘 날씨가 어때요?','지금 날씨가 어때요?')) # non_similar\n",
        "print(sentences_predict('무협 소설 추천해주세요.','무협 장르의 소설 추천 부탁드립니다.')) # similar\n",
        "print(sentences_predict('무협 소설 추천해주세요.','판타지 소설 추천해주세요.')) # non_similar\n",
        "print(sentences_predict('무협 소설 추천해주세요.','무협 느낌나는 소설 하나 추천해주실 수 있으실까요?')) # similar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BydnY73Xf-lV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}