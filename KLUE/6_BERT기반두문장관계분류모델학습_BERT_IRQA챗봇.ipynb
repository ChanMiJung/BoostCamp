{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_BERT기반두문장관계분류모델학습_BERT_IRQA챗봇.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq1RRmMQgb5Z"
      },
      "source": [
        "# BERT IRQA 기반의 챗봇 실습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFFHtKs6hxoI"
      },
      "source": [
        "* [CLS] token을 이용해서 Top-n개를 추출\n",
        "* Top-n개를 하나씩 확인하며 paraphrase detection을 함\n",
        "* paraphrase detection을 하여 question과 나의 query가 유사한 것이 확인되면 A 답변을 return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfOiO3XdgnNY"
      },
      "source": [
        "* 심리 상담 관련 챗봇 데이터 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIOjOae9hFgz"
      },
      "source": [
        "* 데이터 다운로드 및 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYjT2mU7gVAN"
      },
      "source": [
        "!git clone https://github.com/songys/Chatbot_data.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPBDZsoBgssq"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/Chatbot_data/ChatbotData.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRyvN--6hJnO"
      },
      "source": [
        "* single term\n",
        "  * input과 output이 하나로만 구성되어있는 QA dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T76SGzugtOa"
      },
      "source": [
        "data.head()\n",
        "'''\n",
        "\t                        Q\t                 A\tlabel\n",
        "0\t                 12시 땡!\t  하루가 또 가네요.\t    0\n",
        "1\t      1지망 학교 떨어졌어\t   위로해 드립니다.\t    0\n",
        "2\t     3박4일 놀러가고 싶다\t여행은 언제나 좋죠.\t    0\n",
        "3\t3박4일 정도 놀러가고 싶다\t여행은 언제나 좋죠.\t    0\n",
        "4\t               PPL 심하네\t 눈살이 찌푸려지죠.\t    0\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlQgwIwihlRi"
      },
      "source": [
        "## Top-n 추출 모듈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuYAErgVhnUZ"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u9FdAobhoV3"
      },
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p__lPcivho3U"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qenbFCz_hpes"
      },
      "source": [
        "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModel.from_pretrained(MODEL_NAME)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoRcpwRMiWoB"
      },
      "source": [
        "* 데이터 확인\n",
        "  * `chatbot_Question`과 `chatbot_Answer`의 index가 동일한 문장이 서로 pair됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQdW9dAlhrDo"
      },
      "source": [
        "chatbot_Question = data['Q'].values\n",
        "chatbot_Answer = data['A'].values\n",
        "print(chatbot_Question[0:3])\n",
        "# ['12시 땡!' '1지망 학교 떨어졌어' '3박4일 놀러가고 싶다']\n",
        "print(chatbot_Answer[0:3])\n",
        "# ['하루가 또 가네요.' '위로해 드립니다.' '여행은 언제나 좋죠.']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U45EhG7NiGEd"
      },
      "source": [
        "### [CLS] token을 얻기 위한 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dwOjlLdiFW1"
      },
      "source": [
        "def get_cls_token(sent_A):\n",
        "    model.eval()\n",
        "    tokenized_sent = tokenizer(\n",
        "            sent_A,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            max_length=32\n",
        "    ).to(device)\n",
        "    with torch.no_grad():# 그라디엔트 계산 비활성화\n",
        "        outputs = model(\n",
        "            input_ids=tokenized_sent['input_ids'],\n",
        "            attention_mask=tokenized_sent['attention_mask'],\n",
        "            token_type_ids=tokenized_sent['token_type_ids']\n",
        "            )\n",
        "    logits = outputs.last_hidden_state[:,0,:].detach().cpu().numpy()\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap6qz9d8iseD"
      },
      "source": [
        "* 사전에 정의된 모든 sentence에 대한 vector를 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvBAGyNbiaDG"
      },
      "source": [
        "chatbot_Question_vectors = {}\n",
        "for i, question in enumerate(chatbot_Question):\n",
        "    chatbot_Question_vectors[i] = get_cls_token(question)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhzWmnvVi9SB"
      },
      "source": [
        "* 입력 문장 query와 가장 유사한 top-n개 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krVFLZLFibgY"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KQN2S2tjHpP"
      },
      "source": [
        "* cosine similarity를 구하는 함수\n",
        "  * sklearn의 cosine similarity도 사용 가능함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbbmK8UyizKg"
      },
      "source": [
        "def custom_cosine_similarity(a,b):\n",
        "    numerator = np.dot(a,b.T)\n",
        "    a_norm = np.sqrt(np.sum(a * a))\n",
        "    b_norm = np.sqrt(np.sum(b * b, axis=-1))\n",
        "\n",
        "    denominator = a_norm * b_norm\n",
        "    return numerator/denominator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMTFLRO0jDxm"
      },
      "source": [
        "def return_top_n_idx(question, n):\n",
        "    question_vector = get_cls_token(question)\n",
        "    sentence_similarity = {}\n",
        "    for i in chatbot_Question_vectors.keys():\n",
        "        ir_vector = chatbot_Question_vectors[i]\n",
        "        similarity = custom_cosine_similarity(question_vector, ir_vector)\n",
        "        sentence_similarity[i] = similarity\n",
        "    \n",
        "    sorted_sim = sorted(sentence_similarity.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_sim[0:n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5_IxzjfjUA_"
      },
      "source": [
        "print(return_top_n_idx(\"오늘 너무 힘들어\", 5))  # top 5개 question id를 반환합니다.\n",
        "# [(3285, array([[0.97600377]], dtype=float32)), (7121, array([[0.9664848]], dtype=float32)), (5947, array([[0.9598295]], dtype=float32)), (5959, array([[0.95737875]], dtype=float32)), (7176, array([[0.9529198]], dtype=float32))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu79zTVFjoCm"
      },
      "source": [
        "* Top-n의 결과"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krJltkLzjXWB"
      },
      "source": [
        "print('most similar questions')\n",
        "for result in return_top_n_idx(\"오늘 너무 힘들어\", 5):\n",
        "    print(chatbot_Question[result[0]])\n",
        "'''\n",
        "most similar questions\n",
        "오늘 너무 힘들다\n",
        "오늘 너무 힘드네\n",
        "너무 힘들어\n",
        "너무나도 힘들어\n",
        "오늘따라 너무 힘드네\n",
        "'''\n",
        "\n",
        "print('\\nmost similar answers')\n",
        "for result in return_top_n_idx(\"오늘 너무 힘들어\", 5):\n",
        "    print(chatbot_Answer[result[0]])\n",
        "'''\n",
        "most similar answers\n",
        "고생 많았어요.\n",
        "오늘은 힘내려 하지 말아요. 저에게 기대세요.\n",
        "지금 무슨 말을 해도 와닿지 않겠지만 잘할 수 있을 거예요.\n",
        "억지로라도 긍정적인 생각을 해보세요.\n",
        "힘든 날이네요.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lg3UB8ijqT9"
      },
      "source": [
        "* Top-n의 결과\n",
        "  * Top-1의 결과가 정답이 아닌 경우도 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQWtIQz2jg7-"
      },
      "source": [
        "print('most similar questions')\n",
        "for result in return_top_n_idx(\"너 이름이 뭐야?\", 5):\n",
        "    print(chatbot_Question[result[0]])\n",
        "'''\n",
        "most similar questions\n",
        "우정이 뭐야?\n",
        "너 뭐니?\n",
        "할 줄 아는거 뭐야?\n",
        "사랑의 끝이 뭐야?\n",
        "너 누구?\n",
        "'''\n",
        "\n",
        "print('\\nmost similar answers')\n",
        "for result in return_top_n_idx(\"너 이름이 뭐야?\", 5):\n",
        "    print(chatbot_Answer[result[0]])\n",
        "'''\n",
        "most similar answers\n",
        "힘들 때 같이 있는 거요.\n",
        "저는 위로봇입니다.\n",
        "당신의 삶을 응원해 드릴 수 있어요라고 감히 말해 봅니다.\n",
        "사랑하지 않는 것이죠.\n",
        "저는 마음을 이어주는 위로봇입니다.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6E1Rxolj_Kd"
      },
      "source": [
        "## 이진 분류 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi0kLL78kA3q"
      },
      "source": [
        "* Top-n의 결과를 이진 분류 모델을 태워서 실제로 유사한지 검사함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcfCwz6mkmIY"
      },
      "source": [
        "* colab과 나의 google drive를 연결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrLc6tJPkJLu"
      },
      "source": [
        "# 왼쪽 navi에서 폴더icon을 클릭해서 코드 가져올 수 있음\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0ABT_I6kh-4"
      },
      "source": [
        "* 저장된 model을 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOkQFyzMkPNQ"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "MODEL_NAME = \"/content/drive/MyDrive/P_KLUE/baseline_model/bert_two_sent_classifier\"\n",
        "classifier_model = BertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "classifier_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AxhUzNKkezD"
      },
      "source": [
        "# predict함수\n",
        "# 0: \"non_similar\", 1: \"similar\"\n",
        "def sentences_predict(sent_A, sent_B):\n",
        "    classifier_model.eval()\n",
        "    tokenized_sent = tokenizer(\n",
        "            sent_A,\n",
        "            sent_B,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            max_length=64\n",
        "    )\n",
        "    \n",
        "    tokenized_sent.to('cuda:0')\n",
        "    with torch.no_grad():# 그라디엔트 계산 비활성화\n",
        "        outputs = classifier_model(\n",
        "            input_ids=tokenized_sent['input_ids'],\n",
        "            attention_mask=tokenized_sent['attention_mask'],\n",
        "            token_type_ids=tokenized_sent['token_type_ids']\n",
        "            )\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    result = np.argmax(logits)\n",
        "\n",
        "    # if result == 0:\n",
        "    #   result = 'non_similar'\n",
        "    # elif result == 1:\n",
        "    #   result = 'similar'\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oQLNMzhkqy3"
      },
      "source": [
        "print(sentences_predict('오늘 날씨가 어때요?','오늘의 날씨를 알려줘')) # similar\n",
        "print(sentences_predict('오늘 날씨가 어때요?','기분 진짜 안좋다.')) # non_similar\n",
        "print(sentences_predict('오늘 날씨가 어때요?','오늘 기분 어떠세요?')) # non_similar\n",
        "print(sentences_predict('오늘 날씨가 어때요?','오늘 기분이 어때요?')) # non_similar\n",
        "print(sentences_predict('오늘 날씨가 어때요?','지금 날씨가 어때요?')) # non_similar\n",
        "print(sentences_predict('무협 소설 추천해주세요.','무협 장르의 소설 추천 부탁드립니다.')) # similar\n",
        "print(sentences_predict('무협 소설 추천해주세요.','판타지 소설 추천해주세요.')) # non_similar\n",
        "print(sentences_predict('무협 소설 추천해주세요.','무협 느낌나는 소설 하나 추천해주실 수 있으실까요?')) # similar\n",
        "print(sentences_predict('메난민이 뭐야','너 메난민이지?')) # similar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_QvfR8Zk8Cb"
      },
      "source": [
        "* pipeline 합치기\n",
        "  * 두 모듈을 합치기\n",
        "\n",
        "* `return_top_n_idx(question, n)` : input question과 가장 유사한 question n개를 return"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WtNjcMIk6Ll"
      },
      "source": [
        "def get_answer(question, n):\n",
        "    results = return_top_n_idx(question, n) # top n개를 list로 받고\n",
        "    for result in results:  # n개를 반복문을 돌면서\n",
        "        ir_answer = chatbot_Answer[result[0]]\n",
        "        ir_question = chatbot_Question[result[0]]\n",
        "        if sentences_predict(question, ir_question) == 1:   # 이진분류 모델이 query<->question의 의미가 서로 같다고 판단되면?\n",
        "            return ir_answer    # 정답을 반환합니다.\n",
        "    return chatbot_Answer[results[0][0]] # 정답이 없는 경우 top-1이 어떤 답변이든 반환함\n",
        "    # return \"잘 모르겠어요.\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBmQMAVKk68s"
      },
      "source": [
        "print(get_answer(\"너 이름이 뭐야?\", 5))\n",
        "# 저는 위로봇입니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiA-mEkalBeC"
      },
      "source": [
        "print(get_answer(\"나 지금 너무 우울해\", 5))\n",
        "# 꼼꼼한 거예요."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW-Ok9unlxRq"
      },
      "source": [
        "print(get_answer(\"오늘 기분 어때?\", 5))\n",
        "# 숨 쉴만 했으면 좋겠네요."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYYPG5zyl0Bk"
      },
      "source": [
        "print(get_answer(\"바쁜가보네?\", 5))\n",
        "# 직접 확인해보세요."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrFEfrgEl2Cg"
      },
      "source": [
        "print(get_answer(\"어떻게 확인하는데?\", 5))\n",
        "# 잠시 차분하게 생각해봐요."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw-khGzgmFCR"
      },
      "source": [
        "* 챗봇 구성\n",
        "  * IRQA로 사전에 정의된 답변으로 답할 수 있는 경우 답함\n",
        "  * 사전에 정의된 답변으로 답하지 못하는 경우 생성 모델을 통해 답변을 만들어냄"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFJWL6ABl3B4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}