{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_BERT기반두문장관계분류모델학습_학습데이터구축.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqOceSBGSR84"
      },
      "source": [
        "# 두 문장 관계 분류를 위한 학습 데이터 구축"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-RAh9gJSdM5"
      },
      "source": [
        "1. paraphrase를 detection할 수 있는 학습 데이터를 구축\n",
        "2. 이 데이터를 통해서 두 문장 관계 분류를 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlvLxhKJTiMM"
      },
      "source": [
        "* 목적 : paraphrase이 된 데이터과 paraphrase가 되지 않은 데이터 구축"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_GySysiSzet"
      },
      "source": [
        "* paraKQC 데이터\n",
        "  * 하나의 문장에 대해 10개의 유사한 paraphrasing된 문장을 가짐"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmauHxKaTQJo"
      },
      "source": [
        "* 데이터 다운로드 및 관찰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWpk7L1rSLOE"
      },
      "source": [
        "!git clone https://github.com/warnikchow/paraKQC.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZYvj1omTIwd"
      },
      "source": [
        "data = open('/content/paraKQC/data/paraKQC_v1.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD3S53B3TNuO"
      },
      "source": [
        "lines = data.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taQ-CnzcTO11"
      },
      "source": [
        "for i in range(0,15):\n",
        "    print(lines[i]) # 10개씩 paraphasing \n",
        "\n",
        "'''\n",
        "\n",
        "0\t0\t메일을 다 비울까 아니면 안읽은 것만 지울까?\n",
        "\n",
        "0\t0\t메일 중에 안읽은 것만 지울까? 다 지울까?\n",
        "\n",
        "0\t0\t안읽은 메일만 지워 다지워?\n",
        "\n",
        "0\t0\t다 지울까 안읽은 메일만 지울까?\n",
        "\n",
        "0\t0\t전체를 비울까 안읽은 것만 비울까?\n",
        "\n",
        "0\t0\t안읽은 메일만 지울꺼야? 아니면 다 지울꺼야?\n",
        "\n",
        "0\t0\t어떻게 지울까? 안읽은거만? 전체 다?\n",
        "\n",
        "0\t0\t메일을 다 지울지 안읽은거만 지울지 알려주세요\n",
        "\n",
        "0\t0\t메일은 다 지울수도 있고, 안읽은거만 지울 수도 있어. 어떻게 할래?\n",
        "\n",
        "0\t0\t안읽은 메일만 지우든가, 다 지울 수 있는데 어떻게 할꺼야?\n",
        "\n",
        "0\t0\t지메일 쓸래, 네이버 메일 쓸래\n",
        "\n",
        "0\t0\t지메일을 쓸거야 네이버 메일을 쓸꺼야?\n",
        "\n",
        "0\t0\t지메일, 네이버 둘 중에 뭘 쓸래?\n",
        "\n",
        "0\t0\t네이버랑 지메일이 있는데 뭘 쓸래?\n",
        "\n",
        "0\t0\t네이버랑 지메일 중에 골라줄래?\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLg5ZktNTZE2"
      },
      "source": [
        "similar_sents = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_h7ST4xUFFk"
      },
      "source": [
        "* 10개씩 데이터 형태로 묶음\n",
        "  * 전체 문장을 하나씩 읽다가 10개를 읽는 순간 데이터 배열로 10개의 말뭉치를 뺌\n",
        "\n",
        "* `total_sent` : 전체 문장을 저장한 list\n",
        "* `similar_sent` : paraphrasing된 묶음(10개씩 묶음)을 저장한 list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIoNMvLLTZmT"
      },
      "source": [
        "similar_sent = []\n",
        "total_sent = []\n",
        "for line in lines:\n",
        "    line = line.strip()\n",
        "    sent = line.split('\\t')[2]\n",
        "    total_sent.append(sent)\n",
        "    similar_sent.append(sent)\n",
        "    if len(similar_sent) == 10:\n",
        "        similar_sents[similar_sent[0]] = similar_sent[1:]\n",
        "        similar_sent = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhDlqrs0Tawz"
      },
      "source": [
        "print(len(total_sent))  # 가장 유사한 문장을 찾기 위한 전체 문장 pool\n",
        "# 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVUlN2OXT8eY"
      },
      "source": [
        "for i in range(0,15):\n",
        "    print(total_sent[i])\n",
        "\n",
        "'''\n",
        "메일을 다 비울까 아니면 안읽은 것만 지울까?\n",
        "메일 중에 안읽은 것만 지울까? 다 지울까?\n",
        "안읽은 메일만 지워 다지워?\n",
        "다 지울까 안읽은 메일만 지울까?\n",
        "전체를 비울까 안읽은 것만 비울까?\n",
        "안읽은 메일만 지울꺼야? 아니면 다 지울꺼야?\n",
        "어떻게 지울까? 안읽은거만? 전체 다?\n",
        "메일을 다 지울지 안읽은거만 지울지 알려주세요\n",
        "메일은 다 지울수도 있고, 안읽은거만 지울 수도 있어. 어떻게 할래?\n",
        "안읽은 메일만 지우든가, 다 지울 수 있는데 어떻게 할꺼야?\n",
        "지메일 쓸래, 네이버 메일 쓸래\n",
        "지메일을 쓸거야 네이버 메일을 쓸꺼야?\n",
        "지메일, 네이버 둘 중에 뭘 쓸래?\n",
        "네이버랑 지메일이 있는데 뭘 쓸래?\n",
        "네이버랑 지메일 중에 골라줄래?\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHN-N3mHUi6R"
      },
      "source": [
        "print(len(similar_sents)) # 999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAY6HedfU0cz"
      },
      "source": [
        "* 10개의 문장 중 첫 번째 문장을 key, 나머지 문장을 value로 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKfmdXy8Uxzk"
      },
      "source": [
        "for i, key in enumerate(similar_sents.keys()):  # 10개의 문장 중, 첫 번째 문장을 key\n",
        "    print('\\n', key)                            # 나머지 9개의 문장을 value\n",
        "    for sent in similar_sents[key]:             # 헷갈리니까 이걸 similar_sents dict라고 정의할게요 :-)\n",
        "        print(\"-\", sent)\n",
        "    if i > 3:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ApOj768VWHb"
      },
      "source": [
        "* paraphrasing되지 않은 데이터를 구축해야함\n",
        "  * 쉬운 문제 생성\n",
        "    * total_sent 에서 random으로 서로 다른 문장을 선택함\n",
        "    * 의미가 너무 상반된 결과를 가지고 학습하게 됨\n",
        "  * 어려운 문제 생성\n",
        "    * key 문장을 BERT를 통해 sentence embedding함\n",
        "    * total_sent에 있는 문장을 전부 sentence embedding을 한 후 key 문장의 sentence embedding 결과와 가장 유사한 sentence embedding 결과를 가진 문장을 선택함\n",
        "    * sentence embedding은 유사하지만 의미론적으로는 다름"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmzlChB5U985"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STqAjBKsU-tL"
      },
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T9pESUeU_O1"
      },
      "source": [
        "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModel.from_pretrained(MODEL_NAME)\n",
        "model.to('cuda:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4xS5tmyWy0c"
      },
      "source": [
        "* [CLS] token을 가져오고 [CLS] token의 embedding결과를 반환하는 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg7H-dymWkk7"
      },
      "source": [
        "def get_cls_token(sent_A):\n",
        "    model.eval()\n",
        "    tokenized_sent = tokenizer(\n",
        "            sent_A,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            max_length=32\n",
        "    ).to('cuda:0')\n",
        "    with torch.no_grad():# 그라디엔트 계산 비활성화\n",
        "        outputs = model(\n",
        "            input_ids=tokenized_sent['input_ids'],\n",
        "            attention_mask=tokenized_sent['attention_mask'],\n",
        "            token_type_ids=tokenized_sent['token_type_ids']\n",
        "            )\n",
        "    logits = outputs.last_hidden_state[:,0,:].detach().cpu().numpy()\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-E-J0k-Wlbb"
      },
      "source": [
        "print(get_cls_token(\"이순신은 조선 중기의 무신이다.\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I3q2-uEXJPQ"
      },
      "source": [
        "* total_sent 문장 전부 embedding함\n",
        "  * 전체 문장에 대해 각각의 vector 정보가 dict 형태로 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24DqxwsJWnMW"
      },
      "source": [
        "total_sent_vector = {}\n",
        "for i, sent in enumerate(total_sent):   # 전체 문장 pool을 전부 embedding!\n",
        "    total_sent_vector[sent] = get_cls_token(sent)   # {key, value} = {문장, vector}\n",
        "    if i % 500==0:\n",
        "        print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO_v0hycX6n5"
      },
      "source": [
        "* `similar_sents` dictionary의 key값과 total_sent를 전부 비교하여 가장 유사도가 높은 문장을 가져옴"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X-0woNYWoCl"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEU4milvWoq-"
      },
      "source": [
        "def custom_cosine_similarity(a,b):\n",
        "    numerator = np.dot(a,b.T)\n",
        "    a_norm = np.sqrt(np.sum(a * a))\n",
        "    b_norm = np.sqrt(np.sum(b * b, axis=-1))\n",
        "\n",
        "    denominator = a_norm * b_norm\n",
        "    return numerator/denominator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjb9f1CQWpWi"
      },
      "source": [
        "non_similar_sents = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkKYPHWpXDMA"
      },
      "source": [
        "for key in similar_sents.keys():    # similar_sents dict의 sentence를 가져옵니다.\n",
        "    key_sent_vector = total_sent_vector[key]    # 전체 문장 pool에서 해당 sent의 vector을 가져옵니다.\n",
        "    sentence_similarity = {}                    # 다음으로는 전체 문장 pool의 모든 vector와 비교하며\n",
        "    for sent in total_sent:                     # 가장 유사한 문장을 가져옵니다.\n",
        "        if sent not in similar_sents[key] and sent != key: # 9개의 문장에 해당하지 않는지 검사함\n",
        "            sent_vector = total_sent_vector[sent]\n",
        "            similarity = custom_cosine_similarity(key_sent_vector, sent_vector) # 9개의 문장에 해당하지 않으면 cosine similarity로 구함\n",
        "            sentence_similarity[sent] = similarity\n",
        "    sorted_sim = sorted(sentence_similarity.items(), key=lambda x: x[1], reverse=True)\n",
        "    non_similar_sents[key] = sorted_sim[0:10]   # similar_sents dict의 문장과 가장 유사한 10개의 문장을 반환합니다. # TOP-N개 return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwQBEjJKZY4Q"
      },
      "source": [
        "* `non_similar_sents` : 유사하지 않은 set\n",
        "\n",
        "* 각 key에 대해 similarity가 가장 높은 10개 문장 확인\n",
        "  * keyword가 유사하지만 의미론적으로 다름"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oM03qDKXDy3"
      },
      "source": [
        "for i, key in enumerate(non_similar_sents.keys()):\n",
        "    print('\\n', key)\n",
        "    for sent in non_similar_sents[key]:\n",
        "        print(\"-\", sent)\n",
        "    if i > 3:\n",
        "        break\n",
        "\n",
        "'''\n",
        "메일을 다 비울까 아니면 안읽은 것만 지울까?\n",
        "- ('안방 말고 지금 거실 온도 좀 볼 수 있을까?', array([[0.98267]], dtype=float32))\n",
        "- ('안 읽은 메일함이랑 스팸 메일함이랑 비교했을 때 어디가 더 차있지?', array([[0.97837853]], dtype=float32))\n",
        "- ('가습기가 필요한게 아니고 제습기 하나 사야될 것 같지 않아?', array([[0.97624516]], dtype=float32))\n",
        "- ('일월이 바쁘신가요, 아니면 이월이 더 바쁘신가요?', array([[0.97588336]], dtype=float32))\n",
        "- ('안방하고 거실 중에 너가 로봇청소기를 틀고 싶은 곳은 어딜까?', array([[0.97562]], dtype=float32))\n",
        "- ('안방 말고 거실 온도 보려면 어떻게 말해야하나?', array([[0.97547626]], dtype=float32))\n",
        "- ('지금 네가 하고 싶은게 외출모드일까 아님 방범모드일까?', array([[0.9754139]], dtype=float32))\n",
        "- ('메일을 상사에게 어떻게 보내야해?', array([[0.9753622]], dtype=float32))\n",
        "- ('안방 말고 거실 지금 온도 보려면 뭐라고 해야해?', array([[0.9751789]], dtype=float32))\n",
        "- ('목욕물을 개인별로 세팅하고 싶은데요 어떻게 하면 좋을까요?', array([[0.97513217]], dtype=float32))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciKQNgBUaa47"
      },
      "source": [
        "* 데이터 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqeVHawpYFFF"
      },
      "source": [
        "output = open('para_kqc_sim_data.txt', 'w', encoding='utf-8')   # 이걸 데이터로 만들어줍니다 :-)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NReXQPyKYFpr"
      },
      "source": [
        "for i, key in enumerate(similar_sents.keys()):\n",
        "    for sent in similar_sents[key]:\n",
        "        output.write(key + '\\t' + sent + '\\t1\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADi2j8bfYZ6z"
      },
      "source": [
        "for i, key in enumerate(non_similar_sents.keys()):\n",
        "    for sent in non_similar_sents[key]:\n",
        "        output.write(key + '\\t' + sent[0] + '\\t0\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExEL-HRzYajQ"
      },
      "source": [
        "output.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGLmZs4GaYue"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}