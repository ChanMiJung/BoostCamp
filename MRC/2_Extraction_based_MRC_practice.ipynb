{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Extraction_based_MRC_practice.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVTVS9mYXQot"
      },
      "source": [
        "# BERT를 활용해서 Extraction-based MRC 문제 풀기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnWRHZkCWDTd"
      },
      "source": [
        " * GPU 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWO9kJYJVfIu"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4buCdOFMWW8X"
      },
      "source": [
        "* huggingFace 에서 필요한 library 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35HTzU_sWedB"
      },
      "source": [
        "!pip install datasets==1.4.1\n",
        "!pip install transformers==4.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JelE7GMWeJg"
      },
      "source": [
        " * huggingFace 에서 활용할 코드 파일을 git repo에서 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOVBfrjuWupN"
      },
      "source": [
        "# To use utility functions defined in examples.\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%cd transformers\n",
        "!git checkout v4.4.2-release\n",
        "%cd ..\n",
        "import sys\n",
        "sys.path.append('transformers/examples/question-answering')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR7IJEqwXHCe"
      },
      "source": [
        "## 데이터 및 평가 지표 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6qAzo-IWwpl"
      },
      "source": [
        "* 데이터셋 가져오기\n",
        "  * KorQuAD 데이터셋 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imnZFoa8XWPd"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "datasets = load_dataset(\"squad_kor_v1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jICSo4pQXd7h"
      },
      "source": [
        "* 데이터셋 확인\n",
        "  * train과 validation으로 이루어져 있음(각각을 하나의 table로 생각하면 됨)\n",
        "    * features(table의 header)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O11-2pysXfrI"
      },
      "source": [
        "datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuy7CElvYAKf"
      },
      "source": [
        "# access train data \n",
        "datasets['train']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h19DkWOXYCXQ"
      },
      "source": [
        "# access first data\n",
        "datasets['train'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRpQOQAmYKY_"
      },
      "source": [
        "* 데이터셋을 평가하는 function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMCASv9rXaw3"
      },
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric('squad')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17NXkoUNYWK2"
      },
      "source": [
        "## Pre-trained 모델 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z06xe8boYcXv"
      },
      "source": [
        "* AutoConfig : configuration을 불러올 수 있는 class\n",
        "* AutoModelForQuestionAnswering : model을 불러올 수 있는 class\n",
        "* AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g8o_SkmYYcZ"
      },
      "source": [
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForQuestionAnswering,\n",
        "    AutoTokenizer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvgMRCGkYr4r"
      },
      "source": [
        "* model 이름 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0uuO965YuXk"
      },
      "source": [
        "model_name = \"bert-base-multilingual-cased\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvN7JIuOY0fe"
      },
      "source": [
        "* model_name에 해당하는 config, tokenizer, model을 가져옴"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8ZUinpWYvF1"
      },
      "source": [
        "config = AutoConfig.from_pretrained(\n",
        "    model_name\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    use_fast=True\n",
        ")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\n",
        "    model_name,\n",
        "    config=config\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-ubYk7_ZFN0"
      },
      "source": [
        "* model 실제 아키텍처 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_lw1zHFY6Pz"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0A8uE9SZOSG"
      },
      "source": [
        "## 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74848QwwZREM"
      },
      "source": [
        "* max_seq_length\n",
        "  * sequence length의 한계를 알고 있어야 이max_seq_length 내에서 model을 만들고, padding을 정의할 수 있음\n",
        "* pad_to_max_length\n",
        "  * True : max_seq_length 범위 내에서 남는 부분을 padding으로 채워줌\n",
        "* doc_stride\n",
        "  * 나눈 두 문서의 overlap 되는 sequence 길이\n",
        "  * 문서가 너무 긴 경우 문서를 일부 겹치게 하여(overlap) 두 개로 나눔\n",
        "  * 두 개의 문서로 question-answering system을 진행함\n",
        "  * 각각 문서에서 답변을 구한 후 답변을 취합하여 확률이 더 높은 답변을 가져감\n",
        "* max_train_sampels\n",
        "  * 학습할 train 데이터 최대 개수\n",
        "  * max_train_samples 이하의 개수만 학습함\n",
        "  * 값이 작을수록 학습이 빨리 끝남\n",
        "* max_val_sampes\n",
        "  * validation 에 사용될 데이터 최대 개수\n",
        "* preprocessing_num_workers\n",
        "  * 활용할 cpu thread 개수(process 개수)\n",
        "  * 많이 쓸수록 빨라지지만, hardware에 depend하기도 하고, 4 이상으로 필요가 없는 경우도 있음\n",
        "* batch_size\n",
        "  * 학습할 때 사용하는 mini batch size\n",
        "* num_train_epochs\n",
        "  * 학습데이터를 재활용하는 횟수\n",
        "* n_best_size\n",
        "* max_answer_length\n",
        "  * 답변의 최대 길이\n",
        "  * 너무 긴 답변이 나오지 않도록 최대 길이를 제한함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESjjN33LZPvk"
      },
      "source": [
        "max_seq_length = 384 # 질문과 컨텍스트, special token을 합한 문자열의 최대 길이\n",
        "pad_to_max_length = True\n",
        "doc_stride = 128 # 컨텍스트가 너무 길어서 나눴을 때 오버랩되는 시퀀스 길이\n",
        "max_train_samples = 16\n",
        "max_val_samples = 16\n",
        "preprocessing_num_workers = 4\n",
        "batch_size = 4\n",
        "num_train_epochs = 2\n",
        "n_best_size = 20\n",
        "max_answer_length = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIQPeL3CfAHy"
      },
      "source": [
        "## 전처리하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvgKB9trfcgR"
      },
      "source": [
        "* dataset을 적절하게 processing하여 모델에 넣기 적합하게 만듬\n",
        "  * input : dataset들의 각각의 row\n",
        "  * output : BERT의 input 형태"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c8vnqlcfdn7"
      },
      "source": [
        "def prepare_train_features(examples):\n",
        "    # 주어진 텍스트를 토크나이징 한다. 이 때 텍스트의 길이가 max_seq_length를 넘으면 stride만큼 슬라이딩하며 여러 개로 쪼갬.\n",
        "    # 즉, 하나의 example에서 일부분이 겹치는 여러 sequence(feature)가 생길 수 있음.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"context\"],\n",
        "        truncation=\"only_second\",  # max_seq_length까지 truncate한다. pair의 두번째 파트(context)만 잘라냄.\n",
        "        max_length=max_seq_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True, # 길이를 넘어가는 토큰들을 반환할 것인지\n",
        "        return_offsets_mapping=True,  # 각 토큰에 대해 (char_start, char_end) 정보를 반환한 것인지\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    \n",
        "    # example 하나가 여러 sequence에 대응하는 경우를 위해 매핑이 필요함.\n",
        "    overflow_to_sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    # offset_mappings으로 토큰이 원본 context 내 몇번째 글자부터 몇번째 글자까지 해당하는지 알 수 있음.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # 정답지를 만들기 위한 리스트\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "        \n",
        "        # 해당 example에 해당하는 sequence를 찾음.\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        \n",
        "        # sequence가 속하는 example을 찾는다.\n",
        "        example_index = overflow_to_sample_mapping[i]\n",
        "        answers = examples[\"answers\"][example_index]\n",
        "        \n",
        "        # 텍스트에서 answer의 시작점, 끝점\n",
        "        answer_start_offset = answers[\"answer_start\"][0]\n",
        "        answer_end_offset = answer_start_offset + len(answers[\"text\"][0])\n",
        "\n",
        "        # 텍스트에서 현재 span의 시작 토큰 인덱스\n",
        "        token_start_index = 0\n",
        "        while sequence_ids[token_start_index] != 1:\n",
        "            token_start_index += 1\n",
        "        \n",
        "        # 텍스트에서 현재 span 끝 토큰 인덱스\n",
        "        token_end_index = len(input_ids) - 1\n",
        "        while sequence_ids[token_end_index] != 1:\n",
        "            token_end_index -= 1\n",
        "\n",
        "        # answer가 현재 span을 벗어났는지 체크\n",
        "        if not (offsets[token_start_index][0] <= answer_start_offset and offsets[token_end_index][1] >= answer_end_offset):\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # token_start_index와 token_end_index를 answer의 시작점과 끝점으로 옮김\n",
        "            while token_start_index < len(offsets) and offsets[token_start_index][0] <= answer_start_offset:\n",
        "                token_start_index += 1\n",
        "            tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "            while offsets[token_end_index][1] >= answer_end_offset:\n",
        "                token_end_index -= 1\n",
        "            tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbfaCTdkfrDT"
      },
      "source": [
        "train_dataset = datasets[\"train\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyp0N39wf0nH"
      },
      "source": [
        "* 실제 활용할 data를 부분적으로 고름\n",
        "  * max_train_samples 개수만큼 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlPSnrGUfshc"
      },
      "source": [
        "train_dataset = train_dataset.select(range(max_train_samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUQ0iOJUftkU"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp5nZby2gGO1"
      },
      "source": [
        "* dictionary 형태는 BERT의 input 형태가 아니기 때문에 pre-process를 활용하여 BERT input 형태로 변환\n",
        "  * map : train dataset을 매핑함\n",
        "    * prepare_train_features : 사전에 정의한 전처리 함수 사용\n",
        "    * batched\n",
        "      * True : 하나씩 보는 것이 아닌 여러개가 합쳐진 방식으로 보게 됨\n",
        "    * num_proc\n",
        "      * pre-processing을 pipeline화 시킴으로서 processing을 할 때 한번에 하는 것이 아니라 필요할 때마다 ondemand하는 방식을 통해 데이터를 효율적으로 다룸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L452Pq2Bf8mu"
      },
      "source": [
        "column_names = datasets[\"train\"].column_names\n",
        "train_dataset = train_dataset.map( # mapping함\n",
        "            prepare_train_features, # 전처리 함수\n",
        "            batched=True, # 하나씩 보는 것이 아닌 여러개가 합쳐진 방식으로 보게 됨\n",
        "            num_proc=preprocessing_num_workers, \n",
        "            remove_columns=column_names,\n",
        "            load_from_cache_file=True,\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHCsAqFnhN5W"
      },
      "source": [
        "* train dataset 확인\n",
        "  * BERT가 이해할 수 있는 형태로 변형된 것 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_T32YbFhLhs"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_zTrAGVhXXr"
      },
      "source": [
        "* pre-process validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9zGSunahWuB"
      },
      "source": [
        "def prepare_validation_features(examples):\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples['question'],\n",
        "        examples['context'],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=max_seq_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    tokenized_examples[\"example_id\"] = []\n",
        "\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        context_index = 1\n",
        "\n",
        "        sample_index = sample_mapping[i]\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
        "\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\n",
        "            (o if sequence_ids[k] == context_index else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
        "        ]\n",
        "\n",
        "    return tokenized_examples\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDpYcqZRhequ"
      },
      "source": [
        "eval_examples = datasets[\"validation\"]\n",
        "eval_examples = eval_examples.select(range(max_val_samples))\n",
        "eval_dataset = eval_examples.map(\n",
        "            prepare_validation_features,\n",
        "            batched=True,\n",
        "            num_proc=preprocessing_num_workers,\n",
        "            remove_columns=column_names,\n",
        "            load_from_cache_file=True,\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqodxTK4hfjP"
      },
      "source": [
        "## Fine-tuning 하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DEmXlaphusH"
      },
      "source": [
        "* Fine-tuning\n",
        "  * 위키피디아 같은 거대한 corpus를 미리 학습시켜놓은 model을 가져와서 추가적으로 학습\n",
        "\n",
        "* default_data_collator\n",
        "  * 학습할 때 여러 example들을 collact해주는 역할을 함\n",
        "* TrainingArguments\n",
        "  * configuration이나 batch size같은 argument들을 합쳐서 한번에 줄 수 있는 convinient한 function\n",
        "* EvalPrediction\n",
        "  * evaluate할 때 prediction을 쉽게 할 수 있도록 도와주는 function\n",
        "* QuestionAnsweringTrainer\n",
        "  * training할 때 사용\n",
        "  * 편하게 학습 가능\n",
        "* postprocess_qa_predictions\n",
        "  * model에서 나온 답변을 postprocess해줘야함\n",
        "\n",
        "\n",
        "* 앞에서 git repo에서 import 한 파일들에 `trainer_qa`와 `utils_qa`가 포함되어 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHwQObM1hjiL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "24bbb61c-0db7-45a4-b49c-0aa9926dac07"
      },
      "source": [
        "from transformers import default_data_collator, TrainingArguments, EvalPrediction\n",
        "from trainer_qa import QuestionAnsweringTrainer\n",
        "from utils_qa import postprocess_qa_predictions"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-656ad4512ead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefault_data_collator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEvalPrediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrainer_qa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuestionAnsweringTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils_qa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpostprocess_qa_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxKbNJB1jUzj"
      },
      "source": [
        "* 나온 답을 원하는 형태로 mapping해주는 함수 구현\n",
        "  * model이 이해할 수 있는 형태 -> 사람이 이해할 수 있는 형태"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdzPcolfhkbi"
      },
      "source": [
        "def post_processing_function(examples, features, predictions):\n",
        "    # Post-processing: we match the start logits and end logits to answers in the original context.\n",
        "    predictions = postprocess_qa_predictions(\n",
        "        examples=examples,\n",
        "        features=features,\n",
        "        predictions=predictions,\n",
        "        version_2_with_negative=False,\n",
        "        n_best_size=n_best_size,\n",
        "        max_answer_length=max_answer_length,\n",
        "        null_score_diff_threshold=0.0,\n",
        "        output_dir=training_args.output_dir,\n",
        "        is_world_process_zero=trainer.is_world_process_zero(),\n",
        "    )\n",
        "    \n",
        "    # Format the result to the format the metric expects.\n",
        "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in predictions.items()]\n",
        "    references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"validation\"]]\n",
        "    return EvalPrediction(predictions=formatted_predictions, label_ids=references)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxwxOaVejgfZ"
      },
      "source": [
        "* 특정 prediction이 답변과 비교했을 때 얼마나 좋은지 확인하는 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TvOlUJthlcE"
      },
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "    return metric.compute(predictions=p.predictions, references=p.label_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PTOblaAjoXn"
      },
      "source": [
        "* argument 정의\n",
        "  * output_dir\n",
        "    * 내보낼 directory 정의\n",
        "  * do_train\n",
        "    * 학습 진행 여부\n",
        "    * False이면 학습하지 않음\n",
        "  * do_eval\n",
        "    * evaluation 진행 여부\n",
        "    * False이면 evaluation하지 않음\n",
        "  * learning_rate\n",
        "  * per_device_train_batch_size\n",
        "    * 학습할 때의 batch size\n",
        "  * per_device_eval_batch_size\n",
        "    * evaluation할 때의 batch size\n",
        "  * num_train_epochs\n",
        "    * 학습할 때 재사용 횟수\n",
        "  * weight_decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRIuTDzJhmBL"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"outputs\",\n",
        "    do_train=True, \n",
        "    do_eval=True, \n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    weight_decay=0.01,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpKj8CmzkXJA"
      },
      "source": [
        "* 편하게 학습하기 위해 trainer 정의\n",
        "  * model\n",
        "    * model 정의\n",
        "  * args\n",
        "    * 학습할 때 필요한 arguments 정의\n",
        "  * train_dataset\n",
        "    * 학습에 사용되는 dataset 정의\n",
        "    * pre-processing을 통해 model이 이해할 수 있도록 mapping된 dataset\n",
        "  * eval_Dataset\n",
        "    * evaluation에 사용되는 dataset 정의\n",
        "    * pre-processing을 통해 model이 이해할 수 있도록 mapping된 dataset\n",
        "  * eval_examples\n",
        "    * evaluation할 때 사용할 example을 정의\n",
        "  * tokenizer\n",
        "    * tokenizer 정의\n",
        "  * data_collator\n",
        "    * collator 방식(어떻게 example들을 같이 붙여줄지에 대한 방법)\n",
        "    * 대부분 `default_data_collator`를 사용함\n",
        "  * post_process_function\n",
        "    * model output을 사람이 이해하는 형태로 해석하는 방식\n",
        "    * dataset이 아닌 function을 input으로 받음\n",
        "    * 받은 function을 내부에서 활용하여 필요할 때 ondemand로 나온 답변을 사람이 이해할 수 있는 형태로 바꿔줌\n",
        "  * compute_metrics\n",
        "    * evaluation 진행 방식\n",
        "    * function을 input으로 넣어줌"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkcxXlXhhmq0"
      },
      "source": [
        "trainer = QuestionAnsweringTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        eval_examples=datasets[\"validation\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=default_data_collator,\n",
        "        post_process_function=post_processing_function,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A01exVDtl_DW"
      },
      "source": [
        "* 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MyWRo7UhnyU"
      },
      "source": [
        "train_result = trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOCUqEdXmiRs"
      },
      "source": [
        "* 학습확인\n",
        "  * global_step\n",
        "    * 현재 몇 번째 batch를 활용하고 있는가\n",
        "    * 실습에서 12번만 학습하기 때문에 12가 출력됨(학습 끝나고 확인하기 때문에 12만 출력됨)\n",
        "  * training_loss\n",
        "    * 현재 step에서의 loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQBLAmyxh9dj"
      },
      "source": [
        "train_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w74ZO03Tl-SP"
      },
      "source": [
        "## 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi5NJalPmB17"
      },
      "source": [
        "metrics = trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9nCJc3qnBaA"
      },
      "source": [
        "metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzkQfr7ZnEfV"
      },
      "source": [
        "## 학습된 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k_RBEewnJak"
      },
      "source": [
        "finetuned_model = AutoModelForQuestionAnswering.from_pretrained('sangrimlee/bert-base-multilingual-cased-korquad')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2WTWYxwnKjB"
      },
      "source": [
        "finetuned_model = finetuned_model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS4HepuvnLJy"
      },
      "source": [
        "finetuned_trainer = QuestionAnsweringTrainer(\n",
        "    model=finetuned_model,\n",
        "    args=TrainingArguments(\n",
        "        output_dir=\"finetuned_outputs\",\n",
        "        do_eval=True, \n",
        "        per_device_eval_batch_size=batch_size,\n",
        "    ),\n",
        "    train_dataset=None,\n",
        "    eval_dataset=eval_dataset,\n",
        "    eval_examples=datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        "    post_process_function=post_processing_function,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FDPx_xTnNdT"
      },
      "source": [
        "finetuned_metrics = finetuned_trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqmuMFuWnOqL"
      },
      "source": [
        "finetuned_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RbU4BVEnPMJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}