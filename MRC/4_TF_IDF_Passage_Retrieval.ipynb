{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_TF-IDF_Passage_Retrieval.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7sSqK1aiq9f"
      },
      "source": [
        "# TF-IDF를 활용한 Passage Retrieval 실습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la6SFU9JjN8K"
      },
      "source": [
        "* KorQuAD dataset에서 passage를 retrieval하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CwN1WCDiu3W"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH-W_V0tixF8"
      },
      "source": [
        "!pip install datasets\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy8NL89eiwqV"
      },
      "source": [
        "## 데이터셋 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ACEZukAizrQ"
      },
      "source": [
        "* KorQuAD train 데이터셋을 search corpus로 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOsuB4C5i1CG"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"squad_kor_v1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k86hxycjhJ-"
      },
      "source": [
        "* corpus 정의\n",
        "  * 문서들만 가져오기\n",
        "  * 중복된 context들이 있기 때문에 `set()` 후에 `list()`를 취함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJEdfYndi16F"
      },
      "source": [
        "corpus = list(set([example['context'] for example in dataset['train']]))\n",
        "len(corpus) # 9606"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9AwByDYi2eF"
      },
      "source": [
        "## 토크나이저 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL0-qshmj4fa"
      },
      "source": [
        "* 가장 기본적인 띄어쓰기를 기준으로 token을 나누는 tokenizer 정의\n",
        "  * 성능 향상을 위해 더 세밀한 tokenizer 활용 가능함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHFhVb8Hi5Hj"
      },
      "source": [
        "tokenizer_func = lambda x: x.split(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maIxlH68i5sY"
      },
      "source": [
        "tokenizer_func(corpus[0])[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xRDxt6Ji6lF"
      },
      "source": [
        "## TF-IDF embedding 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kNCskxMkUba"
      },
      "source": [
        "* Scikit-learn의 TfidfVectorizer library를 활용하여 TF-IDF embeddind 만들기 (unigram, bigram 활용)\n",
        "  * text를 vector로 바꿔주는 class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6kxGfH3i8-V"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(tokenizer=tokenizer_func, ngram_range=(1,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTSHUINyk251"
      },
      "source": [
        "* `fit()`\n",
        "  * scikit-learn에서 일종의 학습 방법(neural network 학습과는 다름)\n",
        "  * 문서 전체를 보고 IDF에 해당되는 값을 구하고 term을 정의(vocabulary을 만듬)\n",
        "\n",
        "* `transform()`\n",
        "  * corpus를 vector로 바꿔줌"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR2xAIJci9qJ"
      },
      "source": [
        "vectorizer.fit(corpus)\n",
        "sp_matrix = vectorizer.transform(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5V8Tn7Oi-Sn"
      },
      "source": [
        "sp_matrix.shape # (9606, 1272768) # (문서의 수, 지문 내에 등장하는 문서를 전부 가져온 수)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk8pzYYBmLU2"
      },
      "source": [
        "* 첫 번째 문서에 해당되는 값을 table화해서 보여줌(visualize)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR3yyOxPi-yO"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(sp_matrix[0].T.todense(), index=vectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
        "df = df.sort_values('TF-IDF', ascending=False)\n",
        "print(df.head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvM8qIGii_gb"
      },
      "source": [
        "## TF-IDF embedding을 활용하여 passage retrieval 실습하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lucjJODlmOo2"
      },
      "source": [
        "* random하게 하나의 지문을 가져와서 passage retrieval 수행\n",
        "  * 기존 vectorizer를 사용할 것이기 때문에 train dataset에서 가져와야함\n",
        "  * dev에서 가져오는 경우 context가 겹치지 않아서 정답 지문을 찾을 수 없음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRmhpSJ5jDuY"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "random.seed(1)\n",
        "sample_idx = random.choice(range(len(dataset['train'])))\n",
        "\n",
        "query = dataset['train'][sample_idx]['question']\n",
        "ground_truth = dataset['train'][sample_idx]['context']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTP4CR3Jn1pv"
      },
      "source": [
        "* query를 TF-IDF vector로 변환함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EItyRFnLjE-1"
      },
      "source": [
        "query_vec = vectorizer.transform([query])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw5paCmqjFtA"
      },
      "source": [
        "query_vec.shape # (1, 1272768) # 1 : 편의상 matrix로 표현하기 위해 표기함"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnRloz7dn5FH"
      },
      "source": [
        "* 변환된 query vecto를 document들의 vector과 dot product를 수행함 => Document들의 similarity ranking을 구함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3S-yJRkjGaQ"
      },
      "source": [
        "result = query_vec * sp_matrix.T\n",
        "result.shape # (1, 9606) # 9606 : 각 지문과 현재 지문의 유사도를 9606개의 숫자로 나타냄"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whiMg7DjoO3o"
      },
      "source": [
        "* 유사도에서 가장 높은 숫자 찾기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs9Pf53FjG93"
      },
      "source": [
        "sorted_result = np.argsort(-result.data) # 오름차순으로 sort하는 경우 '-'를 붙임\n",
        "doc_scores = result.data[sorted_result] # sorted_result가 index이기 때문에 indexing을 하여 score를 가져옴\n",
        "doc_ids = result.indices[sorted_result]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siMh4SP-onnl"
      },
      "source": [
        "* Top 3 개 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkIAc7H-jH3W"
      },
      "source": [
        "k = 3\n",
        "doc_scores[:k], doc_ids[:k]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02bIU1osjIcZ"
      },
      "source": [
        "print(\"[Search query]\\n\", query, \"\\n\")\n",
        "\n",
        "print(\"[Ground truth passage]\")\n",
        "print(ground_truth, \"\\n\")\n",
        "\n",
        "for i in range(k):\n",
        "  print(\"Top-%d passage with score %.4f\" % (i + 1, doc_scores[i]))\n",
        "  doc_id = doc_ids[i]\n",
        "  print(corpus[doc_id], \"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBv6wf2xikkR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}