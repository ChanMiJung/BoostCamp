{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_Dense_Passage_Retrieval.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbmw-25rS4kC"
      },
      "source": [
        "# BERT를 활용한 Dense Passage Retrieval 실습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci2aKJSxS74L"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiUO7rfTS-GW"
      },
      "source": [
        "!pip install datasets\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44MT5DJVS_G0"
      },
      "source": [
        "## 데이터셋 로딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-M75ErZToWo"
      },
      "source": [
        "* KorQuAD 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvXnGclSTA_r"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"squad_kor_v1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMY9zu-rTB0X"
      },
      "source": [
        "corpus = list(set([example['context'] for example in dataset['train']]))\n",
        "len(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjxzIIlnTCdR"
      },
      "source": [
        "## 토크나이저 준비 - Huggingface 제공 tokenizer 이용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzUxEeFlTtBI"
      },
      "source": [
        "* bert multilingual model 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLcGkw2_TF21"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "model_checkpoint = \"bert-base-multilingual-cased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqbiPq18TGyj"
      },
      "source": [
        "tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tzMhGHTT7WG"
      },
      "source": [
        "* input을 tokenize 및 decoding 하기\n",
        "  * `truncation=True` : 너무 길면 자름"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnBZnaFETHSH"
      },
      "source": [
        "print(corpus[0])\n",
        "tokenized_input = tokenizer(corpus[0], padding=\"max_length\", truncation=True)\n",
        "tokenizer.decode(tokenized_input['input_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMY3P3fyTILb"
      },
      "source": [
        "## Dense encoder (BERT) 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F1Kv_ufUNVi"
      },
      "source": [
        "* package 가져오고 seed 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_YkZ5J3TKl4"
      },
      "source": [
        "from tqdm import tqdm, trange\n",
        "import argparse\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel, BertPreTrainedModel, AdamW, TrainingArguments, get_linear_schedule_with_warmup\n",
        "\n",
        "torch.manual_seed(3532812018032770127)\n",
        "torch.cuda.manual_seed(3532812018032770127)\n",
        "np.random.seed(324)\n",
        "random.seed(2021)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i_LjmlcUhcD"
      },
      "source": [
        "* 학습 데이터 준비\n",
        "  * 128개를 sample 함(총 train 데이터 길이에서 128개 숫자(index)를 sample한 것)\n",
        "  * index로 data를 가져와서 training dataset을 만듬"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gygtb6_jTLao"
      },
      "source": [
        "# Use subset (128 example) of original training dataset \n",
        "sample_idx = np.random.choice(range(len(dataset['train'])), 128)\n",
        "training_dataset = dataset['train'][sample_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RxOg7HMVOUf"
      },
      "source": [
        "* tokenization 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKwZUHuvTN63"
      },
      "source": [
        "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n",
        "\n",
        "q_seqs = tokenizer(training_dataset['question'], padding=\"max_length\", truncation=True, return_tensors='pt')\n",
        "p_seqs = tokenizer(training_dataset['context'], padding=\"max_length\", truncation=True, return_tensors='pt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksQnOBK2Vy2W"
      },
      "source": [
        "* dataset을 학습하기 위해 tenser dataset으로 변경\n",
        "  * q_seqs와 p_seqs를 합쳐주는 것\n",
        "  * 학습할 때 용이하도록(access가 편리함) 형태를 바꾸는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9UdkHvMTPjU"
      },
      "source": [
        "train_dataset = TensorDataset(p_seqs['input_ids'], p_seqs['attention_mask'], p_seqs['token_type_ids'], \n",
        "                        q_seqs['input_ids'], q_seqs['attention_mask'], q_seqs['token_type_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaDb6FV3WMza"
      },
      "source": [
        "* BERT encoder 학습\n",
        "  * BERT encoder를 직접 구현\n",
        "    * [CLS] token에 해당되는 embedding만 가져오면 됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAgLsiS_TQUn"
      },
      "source": [
        "class BertEncoder(BertPreTrainedModel):\n",
        "  def __init__(self, config):\n",
        "    super(BertEncoder, self).__init__(config)\n",
        "\n",
        "    self.bert = BertModel(config)\n",
        "    self.init_weights()\n",
        "      \n",
        "  def forward(self, input_ids, \n",
        "              attention_mask=None, token_type_ids=None): \n",
        "  \n",
        "      # vanilla bert 적용\n",
        "      outputs = self.bert(input_ids,\n",
        "                          attention_mask=attention_mask,\n",
        "                          token_type_ids=token_type_ids)\n",
        "      \n",
        "      pooled_output = outputs[1] # [CLS] token에 해당하는 embedding\n",
        "\n",
        "      return pooled_output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9zCDzOOWz9z"
      },
      "source": [
        "* model을 instantiate하기(시작점 정의)\n",
        "  * model 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjbnlOctTRQX"
      },
      "source": [
        "# load pre-trained model on cuda (if available)\n",
        "p_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
        "q_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
        "\n",
        "if torch.cuda.is_available(): # GPU 사용\n",
        "  p_encoder.cuda()\n",
        "  q_encoder.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL9DWi-SZlJD"
      },
      "source": [
        "* train function 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwfRvbUiTSHq"
      },
      "source": [
        "def train(args, num_neg, dataset, p_model, q_model):\n",
        "  \n",
        "  # Dataloader\n",
        "  train_sampler = RandomSampler(dataset)\n",
        "  ## 학습시 어떻게 학습할지 feeding을 결정함\n",
        "  train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=args.per_device_train_batch_size)\n",
        "\n",
        "  # Optimizer\n",
        "  ## optimizer 관련 parameter 설정\n",
        "  no_decay = ['bias', 'LayerNorm.weight']\n",
        "  optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in p_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
        "        {'params': [p for n, p in p_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
        "        {'params': [p for n, p in q_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
        "        {'params': [p for n, p in q_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "  ## optimizer 정의\n",
        "  optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "  ## 얼마동안 학습할지에 대한 parameter 정의\n",
        "  t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)\n",
        "\n",
        "  # Start training!\n",
        "  global_step = 0\n",
        "  \n",
        "  p_model.zero_grad()\n",
        "  q_model.zero_grad()\n",
        "  torch.cuda.empty_cache()\n",
        "  \n",
        "  train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\")\n",
        "\n",
        "  for _ in train_iterator: ## iteration 시작\n",
        "    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
        "\n",
        "    for step, batch in enumerate(epoch_iterator):\n",
        "      q_encoder.train()\n",
        "      p_encoder.train()\n",
        "      \n",
        "      targets = torch.zeros(args.per_device_train_batch_size).long()\n",
        "      if torch.cuda.is_available():\n",
        "        batch = tuple(t.cuda() for t in batch)\n",
        "        targets = targets.cuda()\n",
        "\n",
        "      p_inputs = {'input_ids': batch[0], ## tensor_dataset을 이용하여 각 batch에 나눠진 값\n",
        "                  'attention_mask': batch[1],\n",
        "                  'token_type_ids': batch[2]\n",
        "                  }\n",
        "      \n",
        "      q_inputs = {'input_ids': batch[3],\n",
        "                  'attention_mask': batch[4],\n",
        "                  'token_type_ids': batch[5]}\n",
        "      \n",
        "      p_outputs = p_model(**p_inputs)  #(batch_size, emb_dim) ## vector의 개수 : batch size\n",
        "      q_outputs = q_model(**q_inputs)  #(batch_size, emb_dim)\n",
        "\n",
        "      # Calculate similarity score & loss\n",
        "      sim_scores = torch.matmul(q_outputs, torch.transpose(p_outputs, 0, 1))  # (batch_size, emb_dim) x (emb_dim, batch_size) = (batch_size, batch_size)\n",
        "\n",
        "      # target: position of positive samples = diagonal element \n",
        "      targets = torch.arange(0, args.per_device_train_batch_size).long()\n",
        "      if torch.cuda.is_available():\n",
        "        targets = targets.to('cuda')\n",
        "\n",
        "      sim_scores = F.log_softmax(sim_scores, dim=1)\n",
        "\n",
        "      loss = F.nll_loss(sim_scores, targets)\n",
        "      print(loss)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      q_model.zero_grad()\n",
        "      p_model.zero_grad()\n",
        "      global_step += 1\n",
        "      \n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    \n",
        "  return p_model, q_model\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AVb5WRXTTA6"
      },
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"dense_retireval\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb5jHMVuTTpo"
      },
      "source": [
        "p_encoder, q_encoder = train(args, num_neg, train_dataset, p_encoder, q_encoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-ah1jzdTUgL"
      },
      "source": [
        "## Dense Embedding을 활용하여 passage retrieval 실습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d41wdMFOZ4wY"
      },
      "source": [
        "* validation set 사용\n",
        "  * train 학습했기 때문"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTT_qMIsTZNw"
      },
      "source": [
        "\n",
        "valid_corpus = list(set([example['context'] for example in dataset['validation']]))[:10]\n",
        "sample_idx = random.choice(range(len(dataset['validation'])))\n",
        "query = dataset['validation'][sample_idx]['question']\n",
        "ground_truth = dataset['validation'][sample_idx]['context']\n",
        "\n",
        "## corpus에 없는 경우 보완함\n",
        "if not ground_truth in valid_corpus:\n",
        "  valid_corpus.append(ground_truth)\n",
        "\n",
        "print(query)\n",
        "print(ground_truth, '\\n\\n')\n",
        "\n",
        "# valid_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58efNsqVTaMU"
      },
      "source": [
        "def to_cuda(batch):\n",
        "  return tuple(t.cuda() for t in batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N7ycYJKaXgS"
      },
      "source": [
        "* 각 passage에 대한 embedding 확보하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfKuYeZOTa2w"
      },
      "source": [
        "with torch.no_grad():\n",
        "  p_encoder.eval()\n",
        "  q_encoder.eval()\n",
        "\n",
        "  q_seqs_val = tokenizer([query], padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
        "  q_emb = q_encoder(**q_seqs_val).to('cpu')  #(num_query, emb_dim)\n",
        "\n",
        "  p_embs = []\n",
        "  for p in valid_corpus:\n",
        "    p = tokenizer(p, padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
        "    p_emb = p_encoder(**p).to('cpu').numpy()\n",
        "    p_embs.append(p_emb)\n",
        "\n",
        "## 하나의 matrix로 변형\n",
        "p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n",
        "\n",
        "print(p_embs.size(), q_emb.size()) ## (11, 768) (1, 768) ## 11 : passage 개수, 768 : embedding size, 1 : question 개수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_UDWa-abYfE"
      },
      "source": [
        "* similarity score 계산하기\n",
        "  * 한 개의 query(question)에 대한 passage들의 유사도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExbzVp_PTcAu"
      },
      "source": [
        "dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
        "print(dot_prod_scores.size())\n",
        "\n",
        "rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze() ## 내림차순 정렬\n",
        "print(dot_prod_scores)\n",
        "print(rank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JkmEzQpTdBn"
      },
      "source": [
        "k = 5\n",
        "print(\"[Search query]\\n\", query, \"\\n\")\n",
        "print(\"[Ground truth passage]\")\n",
        "print(ground_truth, \"\\n\")\n",
        "\n",
        "for i in range(k):\n",
        "  print(\"Top-%d passage with score %.4f\" % (i+1, dot_prod_scores.squeeze()[rank[i]]))\n",
        "  print(valid_corpus[rank[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh-dvtivSuud"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}